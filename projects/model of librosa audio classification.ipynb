{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cbd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993d867",
   "metadata": {},
   "source": [
    "## loading the csv file created using librosa in the preprocessing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc16d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt('x_data.csv', delimiter=',')\n",
    "y = np.loadtxt('y_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a428a",
   "metadata": {},
   "source": [
    "## am using labelEncoder to get the shape of y as of 2 output or categories\n",
    "## i use pandas dataframe to get dummies of the categorical outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16da670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2542d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to for label encoder\n",
    "\n",
    "#labelencoder =  LabelEncoder()\n",
    "#y = labelencoder.to_fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791b3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe for the for the output y\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Gender':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9100b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender\n",
       "0     1.0\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bacea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99381872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0  1.0\n",
       "131    1    0\n",
       "132    1    0\n",
       "133    1    0\n",
       "134    1    0\n",
       "135    1    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23841516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  1.0\n",
       "0    0    1\n",
       "1    0    1\n",
       "2    0    1\n",
       "3    0    1\n",
       "4    0    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41eeae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the dataframe into nummp array\n",
    "\n",
    "y = df_dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f50e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01428357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 40)\n",
      "(136, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6ff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting d data into training and testing dataset\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "306e1091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 40)\n",
      "(28, 40)\n",
      "(108, 2)\n",
      "(28, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d396d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of labels or class required\n",
    "#normally u get using y_train.shape[1] but due to my coding i can'tget it\n",
    "\n",
    "num_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e5c0b",
   "metadata": {},
   "source": [
    "##  building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b036cb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 09:20:36.697097: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-06 09:20:36.931264: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "\n",
    "# first layer\n",
    "\n",
    "model.add(Dense(100, input_shape=(40,)))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# second layer\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# 3rd layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# final layer\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d532506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82a06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed44f46",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8278e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "606b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='audio_classification.hdf5',\n",
    "                              verbose=1, save_best_only=True)\n",
    "\n",
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751824c",
   "metadata": {},
   "source": [
    "## fitting the model on the traing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca47c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 15.9496 - accuracy: 0.4815 \n",
      "Epoch 1: val_loss improved from inf to 4.33111, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 8s 200ms/step - loss: 15.9496 - accuracy: 0.4815 - val_loss: 4.3311 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 11.4089 - accuracy: 0.5417\n",
      "Epoch 2: val_loss improved from 4.33111 to 3.53765, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 11.7917 - accuracy: 0.5278 - val_loss: 3.5376 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 15.6590 - accuracy: 0.5000\n",
      "Epoch 3: val_loss improved from 3.53765 to 1.78990, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 11.6980 - accuracy: 0.5463 - val_loss: 1.7899 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 14.5458 - accuracy: 0.4375\n",
      "Epoch 4: val_loss improved from 1.78990 to 0.48662, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 14.2426 - accuracy: 0.4630 - val_loss: 0.4866 - val_accuracy: 0.8214\n",
      "Epoch 5/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 13.4660 - accuracy: 0.4375\n",
      "Epoch 5: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 7.9803 - accuracy: 0.6019 - val_loss: 0.5091 - val_accuracy: 0.7857\n",
      "Epoch 6/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.8971 - accuracy: 0.6562\n",
      "Epoch 6: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 7.0396 - accuracy: 0.6296 - val_loss: 0.6667 - val_accuracy: 0.6071\n",
      "Epoch 7/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 7.6089 - accuracy: 0.5000\n",
      "Epoch 7: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 7.5517 - accuracy: 0.5370 - val_loss: 1.2275 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 13.0860 - accuracy: 0.4062\n",
      "Epoch 8: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 7.9897 - accuracy: 0.5833 - val_loss: 1.9401 - val_accuracy: 0.5357\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.8280 - accuracy: 0.5463\n",
      "Epoch 9: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 7.8280 - accuracy: 0.5463 - val_loss: 2.1483 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0261 - accuracy: 0.6481\n",
      "Epoch 10: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 4.0261 - accuracy: 0.6481 - val_loss: 1.9860 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.6416 - accuracy: 0.5833\n",
      "Epoch 11: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.6416 - accuracy: 0.5833 - val_loss: 1.5041 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 10.9716 - accuracy: 0.4688\n",
      "Epoch 12: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 8.0054 - accuracy: 0.4907 - val_loss: 0.9083 - val_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.8109 - accuracy: 0.6042\n",
      "Epoch 13: val_loss did not improve from 0.48662\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4538 - accuracy: 0.6019 - val_loss: 0.6097 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.2577 - accuracy: 0.6296\n",
      "Epoch 14: val_loss improved from 0.48662 to 0.48294, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.2577 - accuracy: 0.6296 - val_loss: 0.4829 - val_accuracy: 0.6429\n",
      "Epoch 15/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6636 - accuracy: 0.6146\n",
      "Epoch 15: val_loss did not improve from 0.48294\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.0383 - accuracy: 0.5926 - val_loss: 0.5090 - val_accuracy: 0.6429\n",
      "Epoch 16/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.2125 - accuracy: 0.5625\n",
      "Epoch 16: val_loss did not improve from 0.48294\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.4365 - accuracy: 0.5833 - val_loss: 0.5507 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.9638 - accuracy: 0.6250\n",
      "Epoch 17: val_loss did not improve from 0.48294\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.3593 - accuracy: 0.5463 - val_loss: 0.5494 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 4.1581 - accuracy: 0.5625\n",
      "Epoch 18: val_loss improved from 0.48294 to 0.47046, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.4390 - accuracy: 0.4815 - val_loss: 0.4705 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.7216 - accuracy: 0.5625\n",
      "Epoch 19: val_loss improved from 0.47046 to 0.42564, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 4.3512 - accuracy: 0.5741 - val_loss: 0.4256 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0268 - accuracy: 0.5093\n",
      "Epoch 20: val_loss improved from 0.42564 to 0.41526, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 4.0268 - accuracy: 0.5093 - val_loss: 0.4153 - val_accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.3215 - accuracy: 0.6250\n",
      "Epoch 21: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.4001 - accuracy: 0.6481 - val_loss: 0.4330 - val_accuracy: 0.8929\n",
      "Epoch 22/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.4767 - accuracy: 0.6250\n",
      "Epoch 22: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.7009 - accuracy: 0.5463 - val_loss: 0.4496 - val_accuracy: 0.8929\n",
      "Epoch 23/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.5302 - accuracy: 0.5000\n",
      "Epoch 23: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.1263 - accuracy: 0.5648 - val_loss: 0.4591 - val_accuracy: 0.9643\n",
      "Epoch 24/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.8235 - accuracy: 0.6875\n",
      "Epoch 24: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.2398 - accuracy: 0.6204 - val_loss: 0.4624 - val_accuracy: 0.9643\n",
      "Epoch 25/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.0960 - accuracy: 0.5938\n",
      "Epoch 25: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.5372 - accuracy: 0.5741 - val_loss: 0.4554 - val_accuracy: 0.9643\n",
      "Epoch 26/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.3057 - accuracy: 0.6250\n",
      "Epoch 26: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.2046 - accuracy: 0.6204 - val_loss: 0.4464 - val_accuracy: 0.8929\n",
      "Epoch 27/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.3871 - accuracy: 0.5312\n",
      "Epoch 27: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0721 - accuracy: 0.6481 - val_loss: 0.4511 - val_accuracy: 0.8214\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0780 - accuracy: 0.6111\n",
      "Epoch 28: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.0780 - accuracy: 0.6111 - val_loss: 0.4534 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2981 - accuracy: 0.7037\n",
      "Epoch 29: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2981 - accuracy: 0.7037 - val_loss: 0.4489 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.0110 - accuracy: 0.4688\n",
      "Epoch 30: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.5378 - accuracy: 0.5370 - val_loss: 0.4529 - val_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9660 - accuracy: 0.6574\n",
      "Epoch 31: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.9660 - accuracy: 0.6574 - val_loss: 0.4639 - val_accuracy: 0.8929\n",
      "Epoch 32/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.7770 - accuracy: 0.6875\n",
      "Epoch 32: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9295 - accuracy: 0.6759 - val_loss: 0.4654 - val_accuracy: 0.8929\n",
      "Epoch 33/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4313 - accuracy: 0.6250\n",
      "Epoch 33: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3983 - accuracy: 0.6481 - val_loss: 0.4721 - val_accuracy: 0.8929\n",
      "Epoch 34/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.8665 - accuracy: 0.6250\n",
      "Epoch 34: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.3937 - accuracy: 0.7037 - val_loss: 0.4715 - val_accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9481 - accuracy: 0.6875\n",
      "Epoch 35: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.6080 - accuracy: 0.6759 - val_loss: 0.4680 - val_accuracy: 0.9643\n",
      "Epoch 36/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9658 - accuracy: 0.5938\n",
      "Epoch 36: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0836 - accuracy: 0.6852 - val_loss: 0.4653 - val_accuracy: 0.9286\n",
      "Epoch 37/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4558 - accuracy: 0.5312\n",
      "Epoch 37: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3543 - accuracy: 0.6574 - val_loss: 0.4651 - val_accuracy: 0.8929\n",
      "Epoch 38/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.8663 - accuracy: 0.6875\n",
      "Epoch 38: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2385 - accuracy: 0.6111 - val_loss: 0.4535 - val_accuracy: 0.8929\n",
      "Epoch 39/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.8177 - accuracy: 0.7500\n",
      "Epoch 39: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.7147 - accuracy: 0.6574 - val_loss: 0.4454 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.3615 - accuracy: 0.7500\n",
      "Epoch 40: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5492 - accuracy: 0.6852 - val_loss: 0.4502 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1258 - accuracy: 0.6875\n",
      "Epoch 41: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2531 - accuracy: 0.6481 - val_loss: 0.4596 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4511 - accuracy: 0.6562\n",
      "Epoch 42: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0989 - accuracy: 0.7130 - val_loss: 0.4680 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.6339 - accuracy: 0.5938\n",
      "Epoch 43: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2217 - accuracy: 0.6574 - val_loss: 0.4795 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4784 - accuracy: 0.6250\n",
      "Epoch 44: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2254 - accuracy: 0.6667 - val_loss: 0.4882 - val_accuracy: 0.9643\n",
      "Epoch 45/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5436 - accuracy: 0.7812\n",
      "Epoch 45: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0399 - accuracy: 0.7222 - val_loss: 0.4809 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1032 - accuracy: 0.6875\n",
      "Epoch 46: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.0284 - accuracy: 0.6944 - val_loss: 0.4676 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1244 - accuracy: 0.7812\n",
      "Epoch 47: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1810 - accuracy: 0.7222 - val_loss: 0.4546 - val_accuracy: 0.9643\n",
      "Epoch 48/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0786 - accuracy: 0.8125\n",
      "Epoch 48: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2835 - accuracy: 0.6759 - val_loss: 0.4441 - val_accuracy: 0.9643\n",
      "Epoch 49/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4807 - accuracy: 0.6562\n",
      "Epoch 49: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9432 - accuracy: 0.7037 - val_loss: 0.4379 - val_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7306 - accuracy: 0.6875\n",
      "Epoch 50: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7172 - accuracy: 0.7778 - val_loss: 0.4293 - val_accuracy: 0.9643\n",
      "Epoch 51/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5435 - accuracy: 0.8125\n",
      "Epoch 51: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6508 - accuracy: 0.7685 - val_loss: 0.4215 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0694 - accuracy: 0.6250\n",
      "Epoch 52: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9240 - accuracy: 0.6759 - val_loss: 0.4227 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6500 - accuracy: 0.7812\n",
      "Epoch 53: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7173 - accuracy: 0.7315 - val_loss: 0.4222 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6252 - accuracy: 0.7812\n",
      "Epoch 54: val_loss did not improve from 0.41526\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.6458 - accuracy: 0.8056 - val_loss: 0.4178 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.8115 - accuracy: 0.7188\n",
      "Epoch 55: val_loss improved from 0.41526 to 0.41120, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6632 - accuracy: 0.7593 - val_loss: 0.4112 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5398 - accuracy: 0.7812\n",
      "Epoch 56: val_loss improved from 0.41120 to 0.40502, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7004 - accuracy: 0.7315 - val_loss: 0.4050 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8428 - accuracy: 0.7315\n",
      "Epoch 57: val_loss improved from 0.40502 to 0.40177, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.8428 - accuracy: 0.7315 - val_loss: 0.4018 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.7778\n",
      "Epoch 58: val_loss improved from 0.40177 to 0.39737, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.6700 - accuracy: 0.7778 - val_loss: 0.3974 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7500\n",
      "Epoch 59: val_loss improved from 0.39737 to 0.39044, saving model to audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 81ms/step - loss: 0.6505 - accuracy: 0.7593 - val_loss: 0.3904 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9892 - accuracy: 0.6562\n",
      "Epoch 60: val_loss improved from 0.39044 to 0.38518, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7068 - accuracy: 0.7407 - val_loss: 0.3852 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6697 - accuracy: 0.7812\n",
      "Epoch 61: val_loss improved from 0.38518 to 0.37818, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4510 - accuracy: 0.8241 - val_loss: 0.3782 - val_accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5501 - accuracy: 0.8125\n",
      "Epoch 62: val_loss improved from 0.37818 to 0.37024, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7872 - accuracy: 0.7130 - val_loss: 0.3702 - val_accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6874 - accuracy: 0.7188\n",
      "Epoch 63: val_loss improved from 0.37024 to 0.36520, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7289 - accuracy: 0.7870 - val_loss: 0.3652 - val_accuracy: 0.9643\n",
      "Epoch 64/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6540 - accuracy: 0.7188\n",
      "Epoch 64: val_loss improved from 0.36520 to 0.35254, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.5385 - accuracy: 0.7500 - val_loss: 0.3525 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.8080 - accuracy: 0.7500\n",
      "Epoch 65: val_loss improved from 0.35254 to 0.33901, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.9620 - accuracy: 0.7222 - val_loss: 0.3390 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7528 - accuracy: 0.7500\n",
      "Epoch 66: val_loss improved from 0.33901 to 0.33182, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5934 - accuracy: 0.7778 - val_loss: 0.3318 - val_accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3038 - accuracy: 0.8438\n",
      "Epoch 67: val_loss improved from 0.33182 to 0.32808, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.3425 - accuracy: 0.8333 - val_loss: 0.3281 - val_accuracy: 0.9643\n",
      "Epoch 68/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7320 - accuracy: 0.7500\n",
      "Epoch 68: val_loss improved from 0.32808 to 0.32313, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.5613 - accuracy: 0.8148 - val_loss: 0.3231 - val_accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7500\n",
      "Epoch 69: val_loss improved from 0.32313 to 0.32102, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.4894 - accuracy: 0.8056 - val_loss: 0.3210 - val_accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3372 - accuracy: 0.9375\n",
      "Epoch 70: val_loss did not improve from 0.32102\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5741 - accuracy: 0.8241 - val_loss: 0.3255 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5899 - accuracy: 0.8125\n",
      "Epoch 71: val_loss did not improve from 0.32102\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4440 - accuracy: 0.8333 - val_loss: 0.3278 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5245 - accuracy: 0.7812\n",
      "Epoch 72: val_loss did not improve from 0.32102\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5015 - accuracy: 0.8148 - val_loss: 0.3213 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5519 - accuracy: 0.7188\n",
      "Epoch 73: val_loss improved from 0.32102 to 0.31336, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.5204 - accuracy: 0.7778 - val_loss: 0.3134 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3878 - accuracy: 0.8750\n",
      "Epoch 74: val_loss improved from 0.31336 to 0.30795, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.4853 - accuracy: 0.8241 - val_loss: 0.3080 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2046 - accuracy: 0.9375\n",
      "Epoch 75: val_loss improved from 0.30795 to 0.29896, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2992 - accuracy: 0.8889 - val_loss: 0.2990 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8750\n",
      "Epoch 76: val_loss improved from 0.29896 to 0.28774, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.6629 - accuracy: 0.7963 - val_loss: 0.2877 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3953 - accuracy: 0.8750\n",
      "Epoch 77: val_loss improved from 0.28774 to 0.27627, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5456 - accuracy: 0.8148 - val_loss: 0.2763 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.8056\n",
      "Epoch 78: val_loss improved from 0.27627 to 0.26829, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4594 - accuracy: 0.8056 - val_loss: 0.2683 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8704\n",
      "Epoch 79: val_loss improved from 0.26829 to 0.26320, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.2934 - accuracy: 0.8704 - val_loss: 0.2632 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4249 - accuracy: 0.8438\n",
      "Epoch 80: val_loss improved from 0.26320 to 0.25628, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.4107 - accuracy: 0.8426 - val_loss: 0.2563 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2694 - accuracy: 0.9062\n",
      "Epoch 81: val_loss improved from 0.25628 to 0.24810, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.2631 - accuracy: 0.8889 - val_loss: 0.2481 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.8981\n",
      "Epoch 82: val_loss improved from 0.24810 to 0.24146, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3363 - accuracy: 0.8981 - val_loss: 0.2415 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5823 - accuracy: 0.8125\n",
      "Epoch 83: val_loss improved from 0.24146 to 0.23313, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.4441 - accuracy: 0.8333 - val_loss: 0.2331 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2254 - accuracy: 0.8750\n",
      "Epoch 84: val_loss improved from 0.23313 to 0.22405, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.3531 - accuracy: 0.8241 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5561 - accuracy: 0.7812\n",
      "Epoch 85: val_loss improved from 0.22405 to 0.21646, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.4838 - accuracy: 0.8426 - val_loss: 0.2165 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5780 - accuracy: 0.8125\n",
      "Epoch 86: val_loss improved from 0.21646 to 0.21231, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.3699 - accuracy: 0.8519 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2598 - accuracy: 0.8125\n",
      "Epoch 87: val_loss improved from 0.21231 to 0.20894, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.2784 - accuracy: 0.8611 - val_loss: 0.2089 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3482 - accuracy: 0.8438\n",
      "Epoch 88: val_loss improved from 0.20894 to 0.20526, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.4665 - accuracy: 0.8241 - val_loss: 0.2053 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9062\n",
      "Epoch 89: val_loss improved from 0.20526 to 0.20108, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.3551 - accuracy: 0.8889 - val_loss: 0.2011 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1731 - accuracy: 0.9062\n",
      "Epoch 90: val_loss improved from 0.20108 to 0.19619, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.3969 - accuracy: 0.8519 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9167\n",
      "Epoch 91: val_loss improved from 0.19619 to 0.19311, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2730 - accuracy: 0.9167 - val_loss: 0.1931 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5478 - accuracy: 0.8438\n",
      "Epoch 92: val_loss improved from 0.19311 to 0.19149, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4260 - accuracy: 0.8426 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9062\n",
      "Epoch 93: val_loss improved from 0.19149 to 0.18929, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2897 - accuracy: 0.8889 - val_loss: 0.1893 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4553 - accuracy: 0.8125\n",
      "Epoch 94: val_loss did not improve from 0.18929\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5145 - accuracy: 0.8704 - val_loss: 0.1910 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2948 - accuracy: 0.8646\n",
      "Epoch 95: val_loss did not improve from 0.18929\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2955 - accuracy: 0.8704 - val_loss: 0.1988 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.9167\n",
      "Epoch 96: val_loss did not improve from 0.18929\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1926 - accuracy: 0.9167 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1091 - accuracy: 0.9688\n",
      "Epoch 97: val_loss did not improve from 0.18929\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2876 - accuracy: 0.8704 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2525 - accuracy: 0.9375\n",
      "Epoch 98: val_loss did not improve from 0.18929\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3489 - accuracy: 0.9352 - val_loss: 0.1908 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6446 - accuracy: 0.7188\n",
      "Epoch 99: val_loss improved from 0.18929 to 0.18509, saving model to audio_classification.hdf5\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.4401 - accuracy: 0.8611 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2627 - accuracy: 0.9062\n",
      "Epoch 100: val_loss did not improve from 0.18509\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3463 - accuracy: 0.8889 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "training completed in time 0:00:51.058520\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=num_batch_size, \n",
    "          epochs=num_epochs, validation_data=(x_test, y_test), \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "duration = datetime.now() - start\n",
    "\n",
    "print('training completed in time', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a82475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1857 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1528552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de26abc",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a512812",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt('mercy.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d961779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peopple = x.reshape(1, -1)\n",
    "peopple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bc71813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = x_test[1].reshape(1, -1)\n",
    "p2 = y_test[1]\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a4a36e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = x.reshape(1, -1)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bd98d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= model.predict(peopple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b2df9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43315342, 0.5668466 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04cfec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n"
     ]
    }
   ],
   "source": [
    "if a[0][0] > a[0][1]:\n",
    "    print('female')\n",
    "else:\n",
    "    print('male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27eb2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n"
     ]
    }
   ],
   "source": [
    "for c,d in model.predict(r):\n",
    "    if c > d:\n",
    "        print('female')\n",
    "    else:\n",
    "        print('male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2883119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8aa899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa4899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ccda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6e6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5eaa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373ab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1c28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d426a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32a6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412729d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b1cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e4397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f21c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b12a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea8e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dc6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69b397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b7e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854af9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d0deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be89d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519f637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a29b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a21d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cdf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcfe7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd118819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17be83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bc712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41003f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126199c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919dce68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcce098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb186195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d18f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eada6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09573a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8593c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e10494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67f126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693940ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580d906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58cf95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36eb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d683e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03697c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d15668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932bb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a7629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4546de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90e883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf63f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba048d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3fbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a490fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c066b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe9e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c41347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4fc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107b2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cd309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c4acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
